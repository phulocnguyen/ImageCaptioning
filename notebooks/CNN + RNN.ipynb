{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Captioning using CNN and RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T02:20:48.948846Z",
     "iopub.status.busy": "2024-12-10T02:20:48.948430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.1\n",
      "  Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (24.3.25)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.1)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.62.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (3.11.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.1)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (18.1.1)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13.1)\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.1)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.1)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (2.4.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13.1)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.13.1) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.13.1) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.30.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.1)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.13.1) (3.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.1) (3.2.2)\n",
      "Downloading tensorflow-2.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.15.0\n",
      "    Uninstalling tensorflow-estimator-2.15.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.3\n",
      "    Uninstalling keras-3.3.3:\n",
      "      Successfully uninstalled keras-3.3.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.2.0\n",
      "    Uninstalling google-auth-oauthlib-1.2.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# read text captions\n",
    "\n",
    "def readTextFile(path):\n",
    "    with open(path) as f:\n",
    "        caption = f.read()\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "captions = readTextFile('/kaggle/input/flickr8k/captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "captions = captions.split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "captions[161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "desc = {}\n",
    "\n",
    "for x in captions:\n",
    "    zyzz = x.split(',')\n",
    "    img_name,img_captions= zyzz[0],zyzz[1]\n",
    "    \n",
    "    if desc.get(img_name) is None:\n",
    "        desc[img_name] = []\n",
    "    desc[img_name].append(img_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "desc['1000268201_693b08cb0e.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/flickr8k/Images/1003163366_44323f5815.jpg'\n",
    "plt.imshow(cv2.imread(path))\n",
    "plt.show()\n",
    "desc['1003163366_44323f5815.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "**HERE**\n",
    "- Do not remove stopwords\n",
    "- Do not stemming\n",
    "- Remove numbers, punctuations\n",
    "\n",
    "$X \\rightarrow MODEL \\rightarrow \\textbf{Dense layer with soft max}\\rightarrow vector[\\textbf{probability distribution of each word}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-z]+',' ', sentence)\n",
    "    sentence = sentence.split()\n",
    "    sentence = [s for s in sentence if len(s) > 1]\n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# clean all captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for key, caption_list in desc.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = clean_text(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "desc['1042020065_fb3d3ba5ba.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('/kaggle/working'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# write the data to text file \n",
    "with open('/kaggle/working/descriptions.txt', 'w') as f:\n",
    "    f.write(str(desc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "descriptions = None\n",
    "with open('/kaggle/working/descriptions.txt') as f:\n",
    "    descriptions = f.read()\n",
    "json_acceptable_string = descriptions.replace(\"'\",\"\\\"\")    \n",
    "descriptions = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(type(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "descriptions.get('1042020065_fb3d3ba5ba.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Vocab\n",
    "\n",
    "vocab = set()\n",
    "for key in descriptions.keys():\n",
    "    [vocab.update(sentence.split()) for sentence in descriptions[key]]\n",
    "    \n",
    "print(\"Vocab Size(unique words In Vocab) : %d\"% len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "descriptions.get('1042020065_fb3d3ba5ba.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Total No of words across all the sentences\n",
    "total_words = []\n",
    "\n",
    "for key in descriptions.keys():\n",
    "    [total_words.append(i) for des in descriptions[key] for i in des.split()]\n",
    "    \n",
    "print(\"Total Words %d\"%len(total_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(total_words), type(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# filter words from vocab according to certain threshold frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "counter = collections.Counter(total_words)\n",
    "frq_cnt = dict(counter)\n",
    "print(len(frq_cnt.keys()))\n",
    "# print(frq_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sort the dictionary according to the freq count\n",
    "\n",
    "sorted_freq_cnt = sorted(frq_cnt.items(), reverse = True, key=lambda x:x[1])\n",
    "\n",
    "# filter\n",
    "threshold =  10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(total_words)) # 1800 unique words filter, this is going to be new vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "descriptions.get('1042020065_fb3d3ba5ba.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(descriptions.keys()), len(descriptions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "image_filenames = list(descriptions.keys())\n",
    "\n",
    "random.shuffle(image_filenames)\n",
    "split_index_test = int(0.8 * len(image_filenames))  # 80% for train + val\n",
    "train_val_filenames = image_filenames[:split_index_test]\n",
    "test_filenames = image_filenames[split_index_test:]\n",
    "\n",
    "# Split train + val into train (70%) and val (30%)\n",
    "split_index_val = int(0.7 * len(train_val_filenames))  # 70% for train\n",
    "train_filenames = train_val_filenames[:split_index_val]\n",
    "val_filenames = train_val_filenames[split_index_val:]\n",
    "\n",
    "# Save filenames to their respective files\n",
    "with open('train.txt', 'w') as train_file:\n",
    "    for filename in train_filenames:\n",
    "        train_file.write(f\"{filename}\\n\")\n",
    "\n",
    "with open('val.txt', 'w') as val_file:\n",
    "    for filename in val_filenames:\n",
    "        val_file.write(f\"{filename}\\n\")\n",
    "\n",
    "with open('test.txt', 'w') as test_file:\n",
    "    for filename in test_filenames:\n",
    "        test_file.write(f\"{filename}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_file_data = readTextFile('/kaggle/working/train.txt')\n",
    "val_file_data = readTextFile('/kaggle/working/val.txt')\n",
    "test_file_data = readTextFile('/kaggle/working/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = [row.split('.')[0] for row in train_file_data.split('\\n')[:-1]]\n",
    "val = [row.split('.')[0] for row in val_file_data.split('\\n')[:-1]]\n",
    "test = [row.split('.')[0] for row in test_file_data.split('\\n')[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(descriptions.get('1000268201_693b08cb0e.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if 'image' in train:\n",
    "    train.remove('image')\n",
    "\n",
    "if 'image' in test:\n",
    "    test.remove('image')\n",
    "\n",
    "if 'image' in val:\n",
    "    val.remove('image')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "id = '1000268201_693b08cb0e'\n",
    "descriptions[id+'.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_descriptions = {}\n",
    "for img_id in train:\n",
    "    # print(\"---------------------\")\n",
    "    train_descriptions[img_id] = []\n",
    "    # print(img_id)\n",
    "    # print(descriptions[img_id+'.jpg'])\n",
    "    for cap in descriptions[img_id+'.jpg']:\n",
    "        cap_to_append = \"startseq \" + cap + \" endseq\"\n",
    "        train_descriptions[img_id].append(cap_to_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_descriptions = {}\n",
    "for img_id in val:\n",
    "    # print(\"---------------------\")\n",
    "    val_descriptions[img_id] = []\n",
    "    # print(img_id)\n",
    "    # print(descriptions[img_id+'.jpg'])\n",
    "    for cap in descriptions[img_id+'.jpg']:\n",
    "        cap_to_append = \"startseq \" + cap + \" endseq\"\n",
    "        val_descriptions[img_id].append(cap_to_append)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare Description for the Training Data\n",
    "# Tweak - Add <s> and <e> token to our training data\n",
    "test_descriptions = {}\n",
    "for img_id in test:\n",
    "    # print(\"---------------------\")\n",
    "    test_descriptions[img_id] = []\n",
    "    # print(img_id)\n",
    "    # print(descriptions[img_id+'.jpg'])\n",
    "    for cap in descriptions[img_id+'.jpg']:\n",
    "        cap_to_append = \"startseq \" + cap + \" endseq\"\n",
    "        test_descriptions[img_id].append(cap_to_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "<br>\n",
    "\n",
    "### Step 1: Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ResNet50(weights = 'imagenet', input_shape = (224,224,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_new = Model(model.input,model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img = image.load_img(img,target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    # Normalisation\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img = preprocess_img('/kaggle/input/flickr8k/Images/'+\"1000268201_693b08cb0e.jpg\")\n",
    "plt.imshow(img[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_new.predict(img)  \n",
    "    feature_vector = feature_vector.reshape((2048,))\n",
    "    #print(feature_vector.shape)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encode_image('/kaggle/input/flickr8k/Images/'+\"1000268201_693b08cb0e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_train = {}\n",
    "#image_id -->feature_vector extracted from Resnet Image\n",
    "for ix,img_id in enumerate(train):\n",
    "    img_path = '/kaggle/input/flickr8k/Images/'+\"/\"+img_id+\".jpg\"\n",
    "    encoding_train[img_id] = encode_image(img_path)\n",
    "    if ix%100==0:\n",
    "        print(\"Encoding in progress time step %d \"%ix)\n",
    "end_t = time()\n",
    "print(\"Total Time Taken :\",end_t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_test = {}\n",
    "#image_id -->feature_vector extracted from Resnet Image\n",
    "for ix,img_id in enumerate(test):\n",
    "    img_path = '/kaggle/input/flickr8k/Images'+\"/\"+img_id+\".jpg\"\n",
    "    encoding_test[img_id] = encode_image(img_path)\n",
    "    if ix%100==0:\n",
    "        print(\"Encoding in progress time step %d \"%ix)\n",
    "end_t = time()\n",
    "print(\"Total Time Taken :\",end_t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_val = {}\n",
    "#image_id -->feature_vector extracted from Resnet Image\n",
    "for ix,img_id in enumerate(val):\n",
    "    img_path = '/kaggle/input/flickr8k/Images/'+\"/\"+img_id+\".jpg\"\n",
    "    encoding_val[img_id] = encode_image(img_path)\n",
    "    if ix%100==0:\n",
    "        print(\"Encoding in progress time step %d \"%ix)\n",
    "end_t = time()\n",
    "print(\"Total Time Taken :\",end_t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Store everything to the disk \n",
    "import pickle\n",
    "\n",
    "with open(\"encoded_train_features.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_train,f)\n",
    "\n",
    "with open(\"encoded_val_features.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_val ,f)\n",
    "\n",
    "with open(\"encoded_test_features.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i, word in enumerate(total_words):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word_to_idx['dog']\n",
    "idx_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx_to_word[1801] = 'startseq'\n",
    "word_to_idx['startseq'] = 1801\n",
    "\n",
    "idx_to_word[1802] = 'endseq'\n",
    "word_to_idx['endseq'] = 1802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size =len(word_to_idx)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_len = 0 \n",
    "for key in train_descriptions.keys():\n",
    "    for cap in train_descriptions[key]:\n",
    "        max_len = max(max_len,len(cap.split()))\n",
    "        \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def data_generator(train_descriptions,encoding_train,word_to_idx,max_len,batch_size):\n",
    "    X1,X2, y = [],[],[]\n",
    "    \n",
    "    n = 0\n",
    "    while True:\n",
    "        for key,desc_list in train_descriptions.items():\n",
    "            n += 1\n",
    "            \n",
    "            photo = encoding_train[key]\n",
    "            for desc in desc_list:\n",
    "                \n",
    "                seq = [word_to_idx[word] for word in desc.split() if word in word_to_idx]\n",
    "                for i in range(1,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "                    \n",
    "                    #0 denote padding word\n",
    "                    xi = pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n",
    "                    yi = tf.keras.utils.to_categorical([yi],num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(photo)\n",
    "                    X2.append(xi)\n",
    "                    y.append(yi)\n",
    "                    \n",
    "                if n == batch_size:\n",
    "                    yield [[np.array(X1),np.array(X2)],np.array(y)]\n",
    "                    X1,X2,y = [],[],[]\n",
    "                    n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/kaggle/input/glove/keras/default/1/glove.6B.200d.txt\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    \n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:],dtype='float')\n",
    "    embedding_index[word] = word_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_index['apple'] # embedding for apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "    emb_dim = 200\n",
    "    matrix = np.zeros((vocab_size,emb_dim))\n",
    "    for word,idx in word_to_idx.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_img_features = Input(shape=(2048,))\n",
    "inp_img1 = Dropout(0.5)(input_img_features)\n",
    "inp_img2 = Dense(256,activation='relu')(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Captions as Input\n",
    "from keras.layers import Input, Embedding, Dropout, SimpleRNN\n",
    "input_captions = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=200,mask_zero=True)(input_captions)\n",
    "inp_cap2 = Dropout(0.5)(inp_cap1)\n",
    "inp_cap3 = SimpleRNN(256)(inp_cap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "decoder1 = add([inp_img2,inp_cap3])\n",
    "decoder2 = Dense(256,activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
    "\n",
    "# Combined Model\n",
    "model = Model(inputs=[input_img_features,input_captions],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Embedding Layer most important\n",
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical_crossentropy is used with large no. of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model training \n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "steps = len(train_descriptions)//batch_size + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoding_train['1032122270_ea6f0beedb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.metrics import CategoricalAccuracy\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Track metrics\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracy = CategoricalAccuracy()\n",
    "val_accuracy = CategoricalAccuracy()\n",
    "\n",
    "# BLEU Score Calculation\n",
    "def calculate_bleu(reference, prediction):\n",
    "    reference = [ref.split() for ref in reference]\n",
    "    prediction = prediction.split()\n",
    "    bleu1 = sentence_bleu(reference, prediction, weights=(1, 0, 0, 0))\n",
    "    bleu2 = sentence_bleu(reference, prediction, weights=(0.5, 0.5, 0, 0))\n",
    "    bleu3 = sentence_bleu(reference, prediction, weights=(0.33, 0.33, 0.33, 0))\n",
    "    bleu4 = sentence_bleu(reference, prediction, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    return bleu1, bleu2, bleu3, bleu4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "wandb.login(key=\"269c10a0fe91233f6f807f246ffe2b0daa927a62\") \n",
    "wandb.init(\n",
    "    project=\"image-captioning\",  # Tên dự án của bạn\n",
    "    # name=\"captioning-model-run\",  # Tên phiên bản (run)\n",
    "    config={\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"categorical_crossentropy\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def generate_caption(model, photo, word_to_idx, idx_to_word, max_len):\n",
    "    \"\"\"\n",
    "    Generate a caption for a given image using the trained model.\n",
    "    \n",
    "    :param model: Trained model\n",
    "    :param photo: Feature vector of the image\n",
    "    :param word_to_idx: Mapping of words to their indices\n",
    "    :param idx_to_word: Mapping of indices to their corresponding words\n",
    "    :param max_len: Maximum length of the caption\n",
    "    :return: Generated caption\n",
    "    \"\"\"\n",
    "    in_text = \"startseq\"\n",
    "    for _ in range(max_len):\n",
    "        # Convert the caption into a sequence of indices\n",
    "        sequence = [word_to_idx[word] for word in in_text.split() if word in word_to_idx]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len, padding='post')\n",
    "        \n",
    "        # Predict the next word\n",
    "        yhat = model.predict([photo.reshape(1, 2048), sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        \n",
    "        # Map the predicted index to the word\n",
    "        word = idx_to_word.get(yhat)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += \" \" + word\n",
    "        \n",
    "        # Stop if \"endseq\" is predicted\n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    return in_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu_scores(descriptions, encoding):\n",
    "    bleu1, bleu2, bleu3, bleu4 = 0, 0, 0, 0\n",
    "    total_samples = len(descriptions)\n",
    "\n",
    "    for img_id, refs in descriptions.items():\n",
    "        references = [ref.split() for ref in refs]\n",
    "        predicted_caption = generate_caption(model, encoding[img_id], word_to_idx, idx_to_word, max_len).split()\n",
    "        bleu1 += sentence_bleu(references, predicted_caption, weights=(1, 0, 0, 0))\n",
    "        bleu2 += sentence_bleu(references, predicted_caption, weights=(0.5, 0.5, 0, 0))\n",
    "        bleu3 += sentence_bleu(references, predicted_caption, weights=(0.33, 0.33, 0.33, 0))\n",
    "        bleu4 += sentence_bleu(references, predicted_caption, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "    return bleu1 / total_samples, bleu2 / total_samples, bleu3 / total_samples, bleu4 / total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        train_generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, batch_size)\n",
    "        train_steps = len(train_descriptions) // batch_size\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=train_steps,\n",
    "            verbose=1\n",
    "        )\n",
    "        train_loss = history.history['loss'][-1]\n",
    "        train_acc = history.history.get('accuracy', [0])[-1]\n",
    "\n",
    "        # Validation\n",
    "        val_generator = data_generator(val_descriptions, encoding_val, word_to_idx, max_len, batch_size)\n",
    "        val_steps = len(val_descriptions) // batch_size\n",
    "        val_loss, val_acc = model.evaluate(\n",
    "            val_generator,\n",
    "            steps=val_steps,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc,\n",
    "        })\n",
    "\n",
    "        # Log metrics\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss}, Train Accuracy: {train_acc}\")\n",
    "        print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")\n",
    "\n",
    "        # Save model weights\n",
    "        model.save(f'./model_weights/model_epoch_{epoch+1}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#uncomment to train\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T03:17:03.138434Z",
     "iopub.status.busy": "2024-12-10T03:17:03.138011Z",
     "iopub.status.idle": "2024-12-10T03:17:03.422463Z",
     "shell.execute_reply": "2024-12-10T03:17:03.421375Z",
     "shell.execute_reply.started": "2024-12-10T03:17:03.138392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_generator\u001b[49m(test_descriptions, encoding_test, word_to_idx, max_len, batch_size)\n\u001b[1;32m      2\u001b[0m test_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_descriptions) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m      3\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m      4\u001b[0m     test_generator,\n\u001b[1;32m      5\u001b[0m     steps\u001b[38;5;241m=\u001b[39mtest_steps,\n\u001b[1;32m      6\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator(test_descriptions, encoding_test, word_to_idx, max_len, batch_size)\n",
    "test_steps = len(test_descriptions) // batch_size\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_steps,\n",
    "    verbose=1\n",
    ")\n",
    "test_bleu1, test_bleu2, test_bleu3, test_bleu4 = calculate_bleu_scores(test_descriptions, encoding_test)\n",
    "\n",
    "# Log test metrics to WandB\n",
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_acc,\n",
    "    \"test_bleu1\": test_bleu1,\n",
    "    \"test_bleu2\": test_bleu2,\n",
    "    \"test_bleu3\": test_bleu3,\n",
    "    \"test_bleu4\": test_bleu4,\n",
    "})\n",
    "\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "print(f\"Test BLEU: BLEU-1: {test_bleu1}, BLEU-2: {test_bleu2}, BLEU-3: {test_bleu3}, BLEU-4: {test_bleu4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_caption(photo):\n",
    "    # Initialize the caption with the starting token\n",
    "    in_text = \"startseq\"\n",
    "    for i in range(max_len):\n",
    "        # Convert the current caption to a sequence of indices\n",
    "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
    "        \n",
    "        # Pad the sequence to match the model's input shape\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len, padding='post')\n",
    "        \n",
    "        # Predict the next word\n",
    "        ypred = model.predict([photo, sequence])\n",
    "        ypred = ypred.argmax()  # Get the index of the word with the highest probability\n",
    "        \n",
    "        # Map the predicted index back to a word\n",
    "        word = idx_to_word[ypred]\n",
    "        \n",
    "        # Break if the end token is generated\n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "        \n",
    "        # Append the predicted word to the current caption\n",
    "        in_text += ' ' + word\n",
    "        \n",
    "    # Remove start and end tokens and return the final caption\n",
    "    final_caption = in_text.split()[1:]  # Exclude the start token\n",
    "    return ' '.join(final_caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Max length used in training:\", max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "desc['1003163366_44323f5815.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pick Some Random Images and See Results\n",
    "plt.style.use(\"seaborn\")\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0,1000)\n",
    "    all_img_names = list(encoding_test.keys())\n",
    "    img_name = all_img_names[idx]\n",
    "    photo_2048 = encoding_test[img_name].reshape((1,2048))\n",
    "    \n",
    "    i = plt.imread(\"/kaggle/input/flickr8k/Images/\"+img_name+\".jpg\")\n",
    "    \n",
    "    caption = predict_caption(photo_2048)\n",
    "\n",
    "    image = plt.imread(f\"/kaggle/input/flickr8k/Images/{img_name}.jpg\")\n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"Generated Captions\": wandb.Image(image, caption=caption)}\n",
    "    )\n",
    "    \n",
    "    plt.title(caption)\n",
    "    plt.imshow(i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(encoding_test)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 102312,
     "modelInstanceId": 77688,
     "sourceId": 92656,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
